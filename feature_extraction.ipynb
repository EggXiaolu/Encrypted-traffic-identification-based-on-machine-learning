{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 提取特征值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ijson\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import csv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_file = \"json_data.json\"\n",
    "output_file = \"dataset.csv\"\n",
    "\n",
    "# 用于存储每个流的信息\n",
    "flows = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取文件的总行数\n",
    "def get_file_line_count(file_path):\n",
    "    with open(file_path, \"r\") as f:\n",
    "        return sum(1 for line in f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# total_lines = get_file_line_count(input_file)\n",
    "\n",
    "# 解析 JSON\n",
    "with open(input_file, \"r\", encoding='utf-8') as f:\n",
    "    objects = ijson.items(f, '')\n",
    "    print(objects.__next__())\n",
    "    # for packet in objects:\n",
    "    #     # for packet in tqdm(objects, total=total_lines, desc=\"Processing\"):\n",
    "    #     print(packet)\n",
    "    #     if \"layers\" not in packet:\n",
    "    #         continue\n",
    "\n",
    "    #     layers = packet[\"layers\"]\n",
    "    #     if \"tcp\" not in layers:\n",
    "    #         continue\n",
    "\n",
    "    #     stream_index = layers[\"tcp\"][\"stream\"]\n",
    "    #     payload_length = len(layers[\"tcp\"].get(\"payload\", \"\"))\n",
    "    #     sni = None\n",
    "\n",
    "    #     if \"tls\" in layers:\n",
    "    #         tls_layer = layers[\"tls\"]\n",
    "    #         if (\n",
    "\t# \t\t\t\"handshake\" in tls_layer\n",
    "\t# \t\t\tand tls_layer[\"handshake\"][\"type\"] == \"client_hello\"\n",
    "\t# \t\t):\n",
    "    #             sni = tls_layer[\"handshake\"].get(\"sni\", None)\n",
    "\n",
    "    #     if stream_index not in flows:\n",
    "    #         flows[stream_index] = {\"sni\": sni, \"lengths\": []}\n",
    "\n",
    "    #     if payload_length > 0:\n",
    "    #         flows[stream_index][\"lengths\"].append(payload_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved to dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# 生成最终的 CSV 文件数据\n",
    "data = []\n",
    "for stream_index, flow in flows.items():\n",
    "\tsni = flow[\"sni\"]\n",
    "\tlengths = flow[\"lengths\"][:30] + [0] * (30 - len(flow[\"lengths\"]))\n",
    "\tdata.append([input_file, stream_index, sni] + lengths)\n",
    "\n",
    "# 创建 DataFrame 并保存为 CSV\n",
    "df = pd.DataFrame(\n",
    "\tdata,\n",
    "\tcolumns=[\"filename\", \"stream_index\", \"sni\"] + [f\"len{i}\" for i in range(1, 31)],\n",
    ")\n",
    "df.to_csv(output_file, index=False)\n",
    "\n",
    "print(f\"Dataset saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
